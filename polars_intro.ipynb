{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to [polars](https://pola.rs)\n",
    "\n",
    "A brief introduction to the incredible `polars` dataframe library.\n",
    "\n",
    "![polars logo](https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg)\n",
    "\n",
    "Created by: [Ryan Parker](https://github.com/rparkr), on `2024-08-15`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data analysis in Python\n",
    "As an interpreted language with an easy-to-read syntax, Python is fantastic for data analysis, where rapid iteration enables exploration and accelerates development.\n",
    "\n",
    "Since its first release in 2008, [pandas](https://pandas.pydata.org/docs/) has been the de-facto standard for data analysis in Python, but in recent years other libraries have been created which offer distinct advantages. Some of those include:\n",
    "- [cuDF](https://docs.rapids.ai/api/cudf/stable/): GPU-accelerated dataframe operations with pandas API support\n",
    "- [modin](https://modin.readthedocs.io/en/stable/): pandas API running on distributed compute using [Ray](https://www.ray.io/) or [Dask](https://www.dask.org/) as a backend\n",
    "- [ibis](https://ibis-project.org/): dataframe library supporting dozens of backends (including pandas, polars, DuckDB, and many SQL databases)\n",
    "- [DuckDB](https://duckdb.org/): in-process database engine for running SQL queries on local or remote data\n",
    "- [temporian](https://temporian.readthedocs.io/en/stable/): efficient data processing for timeseries data\n",
    "- [polars](https://pola.rs/): ultra-fast dataframe library written in Rust\n",
    "- and others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Polars advantages\n",
    "- Easy to use\n",
    "- Parallelized across all CPU cores\n",
    "- Zero dependencies\n",
    "- Built on the Apache Arrow in-memory data format: enables zero-copy interoperability with other libraries (e.g., DuckDB, Snowflake)\n",
    "- Handles datasets larger than RAM\n",
    "- Powerful query optimizer\n",
    "- Fully compatible with scikit-learn, thanks to the [Dataframe Interchange Protocol](https://data-apis.org/dataframe-protocol/latest/)\n",
    "- <img src=\"https://www.rust-lang.org/static/images/rust-logo-blk.svg\" width=\"20\"> written in [Rust](https://rust-lang.org), a compiled language that has experienced rapid adoption since its first stable release in 2015 thanks to its C/C++ performance, concurrency, and memory safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key concepts\n",
    "> Polars uses the Apache Arrow data format, which is column-oriented. The primary data structures for polars are Series and DataFrames, similar to pandas.\n",
    "\n",
    "- Apache Arrow supports many useful data types (many more than those which are supported by NumPy), so you can perform fast, vectorized operations on all kinds of data (nested JSON `structs`, strings, datetimes, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contexts\n",
    "In Polars, a _context_ refers to the data available to operate on.\n",
    "\n",
    "The primary contexts are:\n",
    "\n",
    "**Selection**:\n",
    "- `.select()`: choose a subset of columns and perform operations on them\n",
    "- `.with_columns()`: add to the columns already available\n",
    "\n",
    "**Filtering**:\n",
    "- `.filter()`: filter the data using boolean conditions on row values\n",
    "\n",
    "**Aggregation**:\n",
    "- `.group_by()`: perform aggregations on groups of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Expressions\n",
    "_Expressions_ are the operations performed in Polars, things like:\n",
    "- `.sum()`\n",
    "- `.len()`\n",
    "- `.mean().over()...`\n",
    "- `when().then().otherwise()`\n",
    "- `.str.replace()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lazy vs. Eager mode\n",
    "- `scan_csv()` vs. `read_csv()`\n",
    "\n",
    "### Recommendation: use Lazy mode\n",
    "- In Lazy mode, Polars will optimize the query plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plugin ecosystem\n",
    "You can create custom expressions to use in Polars, which will also be vectorized and run in parallel like standard Polars expressions. If there's an operation you'd like to run on your data, chances are someone has already implemented it and it's just a `pip install` away. Here are [some examples](https://docs.pola.rs/user-guide/expressions/plugins/#community-plugins)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [`polars_ds`](https://github.com/abstractqqq/polars_ds_extension): Polars extension for data science tasks\n",
    "> - A combination of functions and operations from scikit-learn, SciPy, and edit distance\n",
    "> - Polars is the only dependency (unless you want to create plots; that adds Plotly as a dependency)\n",
    "> - Can create bar plots within dataframe outputs (HTML `__repr__` in a notebook) -- like sparklines, and similar to what is available in pandas advanced dataframe styling options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [`polars_distance`](https://github.com/ion-elgreco/polars-distance): distance calculations (e.g., word similarity) in polars\n",
    "> also includes haversine distance (lat/lon), cosine similarity, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [`polars_reverse_geocode`](https://github.com/MarcoGorelli/polars-reverse-geocode): offline reverse geocoding\n",
    "> find a city based on provided lat/lon; using an offline lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tutorial: [how to create a polars plugin](https://marcogorelli.github.io/polars-plugins-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final thoughts\n",
    "\n",
    "## Upgrade weekly\n",
    "‚≠ê Polars development [advances rapidly](https://github.com/pola-rs/polars/releases), so I recommend upgrading often (weekly) to get the latest features\n",
    "\n",
    "## Try it out\n",
    "The best way to learn is by doing. Try using Polars any time you create a new notebook or start a new project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "- [Polars user guide](https://docs.pola.rs/user-guide/migration/pandas/): fantastic guide to learning Polars alongside helpful explanations\n",
    "- [Coming from `pandas`](https://docs.pola.rs/user-guide/migration/pandas/): are you familiar with `pandas` and want to learn the differences you'll notice when switching to polars? This guide translates common concepts to help you.\n",
    "  - [This series of articles from 2022](https://kevinheavey.github.io/modern-polars/) demonstrates some operations in pandas and polars, side-by-side. _Polars development advances rapidly, so many of the concepts covered in that series are already different. Still it will help you get a general feel for the flow of using Polars compared to pandas._\n",
    "- [Polars Python API](https://docs.pola.rs/api/python/stable/reference/index.html): detailed info on every expression, method, and function in Polars. I recommend browsing this list to get a feel for what Polars can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "In this section, I demonstrate basic Polars usage on the NYC Taxi Yellow Cab dataset. You can find more information about that dataset on the [NYC Trip Record Data page](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "\n",
    "## Data dictionary (taken from the [PDF file published by NYC Trip Record Data](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)):\n",
    "1. VendorID: A code indicating the TPEP provider that provided the record. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.\n",
    "2. tpep_pickup_datetime: The date and time when the meter was engaged\n",
    "3. tpep_dropoff_datetime: The date and time when the meter was disengaged\n",
    "4. Passenger_count: The number of passengers in the vehicle. This is a driver-entered value.\n",
    "5. Trip_distance: The elapsed trip distance in miles reported by the taximeter\n",
    "6. PULocationID: TLC Taxi Zone in which the taximeter was engaged\n",
    "    - [See here](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml) for a map of the TLC Taxi Zones\n",
    "7. DOLocationID: TLC Taxi Zone in which the taximeter was disengaged\n",
    "8. RateCodeID: The final rate code in effect at the end of the trip.\n",
    "    - 1 = Standard rate\n",
    "    - 2 = JFK\n",
    "    - 3 = Newark\n",
    "    - 4 = Nassau or Westchester\n",
    "    - 5 = Negotiated fare\n",
    "    - 6 = Group ride\n",
    "9. Store_and_fwd_flag: This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka ‚Äústore and forward,‚Äù because the vehicle did not have a connection to the server\n",
    "    - Y = store and forward trip\n",
    "    - N = not a store and forward trip\n",
    "10. Payment_type: A numeric code signifying how the passenger paid for the trip\n",
    "    - 1 = Credit card\n",
    "    - 2 = Cash\n",
    "    - 3 = No charge\n",
    "    - 4 = Dispute\n",
    "    - 5 = Unknown\n",
    "    - 6 = Voided trip\n",
    "11. Fare_amount: The time-and-distance fare calculated by the meter\n",
    "12. Extra: Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.\n",
    "13. MTA_tax: $0.50 MTA tax that is automatically triggered based on the metered rate in use\n",
    "14. Improvement_surcharge: $0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.\n",
    "15. Tip_amount: Tip amount ‚Äì This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "16. Tolls_amount: Total amount of all tolls paid in trip.\n",
    "17. Total_amount: The total amount charged to passengers. Does not include cash tips\n",
    "18. Congestion_Surcharge: Total amount collected in trip for NYS congestion surcharge.\n",
    "19. Airport_fee: $1.25 for pick up only at LaGuardia and John F. Kennedy Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy-load the data\n",
    "Polar can read Parquet files (local or hosted on a network), determine their schema (columns), apply filter pushdowns, and only downloaded the data that is needed for the operations being performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files we'll work with:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Files are published monthly, with a 2-month delay. For simplicity,\n",
    "# I use a 3-month delay to ensure that the data is available.\n",
    "def get_data_urls(year: int=None) -> list[str]:\n",
    "    \"\"\"Get the URLs for all months of Yellow Taxi data in a given year.\"\"\"\n",
    "    if not year:\n",
    "        year = dt.date.today().year\n",
    "    current_year = dt.date.today().year\n",
    "    assert (year >= 2009) and (year <= current_year), (\n",
    "        f\"year must be >= 2009 and <= {current_year}, but {year} was given\"\n",
    "    )\n",
    "    end_month = 12 \n",
    "    if year == current_year:\n",
    "        if dt.date.today().month <= 3:\n",
    "            print(\n",
    "                \"The current year was requested, but data may not yet \"\n",
    "                f\"be available. Using last year ({current_year - 1}) instead.\"\n",
    "            )\n",
    "            year = current_year - 1\n",
    "        else:\n",
    "            end_month = dt.date.today().month - 3\n",
    "    data_urls = [\n",
    "        f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month:0>2d}.parquet\"\n",
    "        for month\n",
    "        in range(1, end_month + 1)\n",
    "    ]\n",
    "    return data_urls\n",
    "\n",
    "print(\"Here are the files we'll work with:\")\n",
    "get_data_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LazyFrame that will use the data from all the files specified above\n",
    "df = pl.scan_parquet(get_data_urls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('VendorID', Int32),\n",
       "        ('tpep_pickup_datetime', Datetime(time_unit='ns', time_zone=None)),\n",
       "        ('tpep_dropoff_datetime', Datetime(time_unit='ns', time_zone=None)),\n",
       "        ('passenger_count', Int64),\n",
       "        ('trip_distance', Float64),\n",
       "        ('RatecodeID', Int64),\n",
       "        ('store_and_fwd_flag', String),\n",
       "        ('PULocationID', Int32),\n",
       "        ('DOLocationID', Int32),\n",
       "        ('payment_type', Int64),\n",
       "        ('fare_amount', Float64),\n",
       "        ('extra', Float64),\n",
       "        ('mta_tax', Float64),\n",
       "        ('tip_amount', Float64),\n",
       "        ('tolls_amount', Float64),\n",
       "        ('improvement_surcharge', Float64),\n",
       "        ('total_amount', Float64),\n",
       "        ('congestion_surcharge', Float64),\n",
       "        ('Airport_fee', Float64)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out what columns are available and their data types\n",
    "df.collect_schema()\n",
    "\n",
    "# If this were a local Parquet file, you could get just the schema\n",
    "# without reading data:\n",
    "# pl.read_parquet_schema(\"path/to/a/local/file.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th></tr><tr><td>i32</td><td>datetime[ns]</td><td>datetime[ns]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2024-01-01 00:57:55</td><td>2024-01-01 01:17:43</td><td>1</td><td>1.72</td><td>1</td><td>&quot;N&quot;</td><td>186</td><td>79</td><td>2</td><td>17.7</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.7</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:03:00</td><td>2024-01-01 00:09:36</td><td>1</td><td>1.8</td><td>1</td><td>&quot;N&quot;</td><td>140</td><td>236</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>3.75</td><td>0.0</td><td>1.0</td><td>18.75</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:17:06</td><td>2024-01-01 00:35:01</td><td>1</td><td>4.7</td><td>1</td><td>&quot;N&quot;</td><td>236</td><td>79</td><td>1</td><td>23.3</td><td>3.5</td><td>0.5</td><td>3.0</td><td>0.0</td><td>1.0</td><td>31.3</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:36:38</td><td>2024-01-01 00:44:56</td><td>1</td><td>1.4</td><td>1</td><td>&quot;N&quot;</td><td>79</td><td>211</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>17.0</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:46:51</td><td>2024-01-01 00:52:57</td><td>1</td><td>0.8</td><td>1</td><td>&quot;N&quot;</td><td>211</td><td>148</td><td>1</td><td>7.9</td><td>3.5</td><td>0.5</td><td>3.2</td><td>0.0</td><td>1.0</td><td>16.1</td><td>2.5</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ VendorID ‚îÜ tpep_pick ‚îÜ tpep_drop ‚îÜ passenger ‚îÜ ‚Ä¶ ‚îÜ improveme ‚îÜ total_amo ‚îÜ congestio ‚îÜ Airport_f ‚îÇ\n",
       "‚îÇ ---      ‚îÜ up_dateti ‚îÜ off_datet ‚îÜ _count    ‚îÜ   ‚îÜ nt_surcha ‚îÜ unt       ‚îÜ n_surchar ‚îÜ ee        ‚îÇ\n",
       "‚îÇ i32      ‚îÜ me        ‚îÜ ime       ‚îÜ ---       ‚îÜ   ‚îÜ rge       ‚îÜ ---       ‚îÜ ge        ‚îÜ ---       ‚îÇ\n",
       "‚îÇ          ‚îÜ ---       ‚îÜ ---       ‚îÜ i64       ‚îÜ   ‚îÜ ---       ‚îÜ f64       ‚îÜ ---       ‚îÜ f64       ‚îÇ\n",
       "‚îÇ          ‚îÜ datetime[ ‚îÜ datetime[ ‚îÜ           ‚îÜ   ‚îÜ f64       ‚îÜ           ‚îÜ f64       ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ ns]       ‚îÜ ns]       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 2        ‚îÜ 2024-01-0 ‚îÜ 2024-01-0 ‚îÜ 1         ‚îÜ ‚Ä¶ ‚îÜ 1.0       ‚îÜ 22.7      ‚îÜ 2.5       ‚îÜ 0.0       ‚îÇ\n",
       "‚îÇ          ‚îÜ 1         ‚îÜ 1         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ 00:57:55  ‚îÜ 01:17:43  ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ 1        ‚îÜ 2024-01-0 ‚îÜ 2024-01-0 ‚îÜ 1         ‚îÜ ‚Ä¶ ‚îÜ 1.0       ‚îÜ 18.75     ‚îÜ 2.5       ‚îÜ 0.0       ‚îÇ\n",
       "‚îÇ          ‚îÜ 1         ‚îÜ 1         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ 00:03:00  ‚îÜ 00:09:36  ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ 1        ‚îÜ 2024-01-0 ‚îÜ 2024-01-0 ‚îÜ 1         ‚îÜ ‚Ä¶ ‚îÜ 1.0       ‚îÜ 31.3      ‚îÜ 2.5       ‚îÜ 0.0       ‚îÇ\n",
       "‚îÇ          ‚îÜ 1         ‚îÜ 1         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ 00:17:06  ‚îÜ 00:35:01  ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ 1        ‚îÜ 2024-01-0 ‚îÜ 2024-01-0 ‚îÜ 1         ‚îÜ ‚Ä¶ ‚îÜ 1.0       ‚îÜ 17.0      ‚îÜ 2.5       ‚îÜ 0.0       ‚îÇ\n",
       "‚îÇ          ‚îÜ 1         ‚îÜ 1         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ 00:36:38  ‚îÜ 00:44:56  ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ 1        ‚îÜ 2024-01-0 ‚îÜ 2024-01-0 ‚îÜ 1         ‚îÜ ‚Ä¶ ‚îÜ 1.0       ‚îÜ 16.1      ‚îÜ 2.5       ‚îÜ 0.0       ‚îÇ\n",
       "‚îÇ          ‚îÜ 1         ‚îÜ 1         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îÇ          ‚îÜ 00:46:51  ‚îÜ 00:52:57  ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first few rows.\n",
    "\n",
    "# This is a somewhat expensive operation, since all files will need to be\n",
    "# queried. I ran this previously to save the output in the notebook, then\n",
    "# commented out the line below.\n",
    "# df.head().collect()\n",
    "\n",
    "# With an in-memory DataFrame, you can run: df.glimpse() for a more compact\n",
    "# view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATE\n",
      "\t[len().alias(\"num_trips\"), col(\"total_amount\").mean().alias(\"cost_per_trip\"), col(\"passenger_count\").mean().alias(\"avg_passengers_per_trip\"), col(\"trip_distance\").mean().alias(\"avg_distance\"), [(col(\"Airport_fee\")) > (0.0)].sum().alias(\"num_airport_trips\")] BY [col(\"tpep_pickup_datetime\").dt.to_string().alias(\"by\")] FROM\n",
      "  Parquet SCAN [https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet, ... 5 other files]\n",
      "  PROJECT 5/19 COLUMNS\n",
      "  SELECTION: [(col(\"tpep_pickup_datetime\").dt.month()) <= (3)]\n"
     ]
    }
   ],
   "source": [
    "# Find the average cost per trip, by month\n",
    "# Note that the operations below are performed in parallel across\n",
    "# all available CPU cores, and that only the data needed will be downloaded.\n",
    "# In the case, since I have filtered to 3 months, only those months of data\n",
    "# will be downloaded. Also notice that only 5 columns will be downloaded, since\n",
    "# those are the ones I have requested.\n",
    "query_plan = df.filter(\n",
    "    pl.col(\"tpep_pickup_datetime\").dt.month() <= 3\n",
    ").group_by(\n",
    "    by=pl.col(\"tpep_pickup_datetime\").dt.strftime(\"%Y-%m\").alias(\"month\")\n",
    ").agg(\n",
    "    num_trips=pl.len(),  # count the number of trips\n",
    "    cost_per_trip=pl.col(\"total_amount\").mean(),\n",
    "    avg_passengers_per_trip=pl.col(\"passenger_count\").mean(),\n",
    "    avg_distance=pl.col(\"trip_distance\").mean(),\n",
    "    num_airport_trips=(pl.col(\"Airport_fee\") > 0).sum(),\n",
    ").sort(\n",
    "    pl.col(\"month\")\n",
    ")\n",
    "\n",
    "# See what Polars will execute\n",
    "print(query_plan.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, run the query. This uses ~150MB of data transfer.\n",
    "df_avg = query_plan.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>by</th><th>num_trips</th><th>cost_per_trip</th><th>avg_passengers_per_trip</th><th>avg_distance</th><th>num_airport_trips</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;2024-01&quot;</td><td>2964617</td><td>26.801505</td><td>1.339277</td><td>3.652169</td><td>232750</td></tr><tr><td>&quot;2009-01&quot;</td><td>9</td><td>43.978889</td><td>1.555556</td><td>7.248889</td><td>4</td></tr><tr><td>&quot;2024-03&quot;</td><td>3582611</td><td>27.120594</td><td>1.337624</td><td>4.517421</td><td>263650</td></tr><tr><td>&quot;2024-02&quot;</td><td>3007533</td><td>26.624412</td><td>1.325943</td><td>3.860858</td><td>213012</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 6)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ by      ‚îÜ num_trips ‚îÜ cost_per_trip ‚îÜ avg_passengers_per_trip ‚îÜ avg_distance ‚îÜ num_airport_trips ‚îÇ\n",
       "‚îÇ ---     ‚îÜ ---       ‚îÜ ---           ‚îÜ ---                     ‚îÜ ---          ‚îÜ ---               ‚îÇ\n",
       "‚îÇ str     ‚îÜ u32       ‚îÜ f64           ‚îÜ f64                     ‚îÜ f64          ‚îÜ u32               ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 2024-01 ‚îÜ 2964617   ‚îÜ 26.801505     ‚îÜ 1.339277                ‚îÜ 3.652169     ‚îÜ 232750            ‚îÇ\n",
       "‚îÇ 2009-01 ‚îÜ 9         ‚îÜ 43.978889     ‚îÜ 1.555556                ‚îÜ 7.248889     ‚îÜ 4                 ‚îÇ\n",
       "‚îÇ 2024-03 ‚îÜ 3582611   ‚îÜ 27.120594     ‚îÜ 1.337624                ‚îÜ 4.517421     ‚îÜ 263650            ‚îÇ\n",
       "‚îÇ 2024-02 ‚îÜ 3007533   ‚îÜ 26.624412     ‚îÜ 1.325943                ‚îÜ 3.860858     ‚îÜ 213012            ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
